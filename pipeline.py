# -*- coding: utf-8 -*-
"""pipeline.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZevcmrjUUSr05uqApqcHOyu19wnZ1Mad
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score
from xgboost import XGBClassifier
import matplotlib.pyplot as plt
import joblib

# Load data
df = pd.read_csv("WA_Fn-UseC_-Telco-Customer-Churn.csv")

# Drop customerID (non-informative)
df.drop("customerID", axis=1, inplace=True)

# Convert TotalCharges to numeric
df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")

# Handle missing values
df["TotalCharges"].fillna(df["TotalCharges"].median(), inplace=True)

# Target variable
df["Churn"] = df["Churn"].map({"Yes": 1, "No": 0})
y = df["Churn"]
X = df.drop("Churn", axis=1)

# Feature categories
numerical_cols = ["tenure", "MonthlyCharges", "TotalCharges"]
categorical_cols = X.select_dtypes(include=["object"]).columns.tolist()

# Preprocessing
numeric_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

categorical_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("encoder", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer([
    ("num", numeric_pipeline, numerical_cols),
    ("cat", categorical_pipeline, categorical_cols)
])

# Final pipeline with model
model_pipeline = Pipeline([
    ("preprocessing", preprocessor),
    ("classifier", XGBClassifier(use_label_encoder=False, eval_metric="logloss", random_state=42))
])

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# Fit model
model_pipeline.fit(X_train, y_train)

# Evaluate
y_proba = model_pipeline.predict_proba(X_test)[:, 1]
roc_auc = roc_auc_score(y_test, y_proba)
avg_precision = average_precision_score(y_test, y_proba)

print(f"ROC AUC Score: {roc_auc:.4f}")
print(f"Average Precision (PR AUC): {avg_precision:.4f}")

# Plot Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_proba)
plt.plot(recall, precision, label="PR Curve")
plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision-Recall Curve")
plt.legend()
plt.grid()
plt.show()

# Save model
joblib.dump(model_pipeline, "churn_model.joblib")